{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# !pip install selenium"],"metadata":{"id":"gISE-HZ49X08"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import requests\n","from bs4 import BeautifulSoup\n","import re\n","from selenium import webdriver\n","from selenium.webdriver.chrome.options import Options\n","from selenium.webdriver.common.by import By\n","from selenium.common.exceptions import ElementClickInterceptedException, NoSuchElementException\n","import time\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt"],"metadata":{"id":"0JmiLiOa4DFf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 1. Web Scraping from Rotten Tomatoes"],"metadata":{"id":"BuwHpJJhfiAj"}},{"cell_type":"code","source":["def scrape_rotten_tomatoes(movie_names):\n","    # Configure Chrome options\n","    options = Options()\n","    options.add_argument(\"--start-maximized\")\n","    options.add_argument(\"--disable-blink-features=AutomationControlled\")\n","    options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n","    options.add_experimental_option(\"useAutomationExtension\", False)\n","    options.add_argument(\"--headless\")  # Run in background\n","\n","    # Initialize the driver\n","    driver = webdriver.Chrome(options=options)\n","\n","    full_results = {}\n","    for movie in movie_names:\n","        movie = movie.lower().replace(\" \",\"_\")\n","        movie = re.sub(r'[^\\w_]', '', movie)\n","        url = f\"https://www.rottentomatoes.com/m/{movie}\"\n","        results = {}\n","        try:\n","            # Go to the page\n","            driver.get(url)\n","            # Optionally add a sleep here if necessary:\n","            # time.sleep(1)\n","\n","            # Find the critics score directly using the identified selector\n","            score_element = driver.find_element(By.CSS_SELECTOR, 'rt-text[slot=\"criticsScore\"]')\n","            audience_element = driver.find_element(By.CSS_SELECTOR, 'rt-text[slot=\"audienceScore\"]')\n","\n","            # Extract and convert the text from the element\n","            critics_score = int(score_element.text.strip().replace(\"%\", \"\"))\n","            audience_score = int(audience_element.text.strip().replace(\"%\", \"\"))\n","\n","            results[\"critic score\"] = critics_score\n","            results[\"audience score\"] = audience_score\n","\n","            # Find all <dt> (keys) and <dd> (values)\n","            keys = driver.find_elements(By.CSS_SELECTOR, \"dl div dt\")\n","            values = driver.find_elements(By.CSS_SELECTOR, \"dl div dd\")\n","\n","            for key, value in zip(keys, values):\n","                key_text = key.text.strip()\n","                # Find all value items (could be rt-text or rt-link)\n","                value_items = value.find_elements(By.CSS_SELECTOR, 'rt-text[data-qa=\"item-value\"], rt-link[data-qa=\"item-value\"]')\n","                # Join multiple values into one string\n","                value_text = \", \".join(v.text.strip() for v in value_items if v.text.strip())\n","                results[key_text] = value_text\n","\n","            # Only add this movie if it has a Box Office value (non-empty)\n","            if \"audience score\" in results and results[\"audience score\"]:\n","                full_results[movie] = results\n","\n","        except Exception as e:\n","            #print(f\"Error processing {movie}\")\n","            pass\n","\n","    driver.quit()\n","    return full_results"],"metadata":{"id":"VjC0a5_ufYpD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"RDkj9dJ9fZdw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["See another notebook"],"metadata":{"id":"Gn38qEoD8MeM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 2. Sentiment Analysis on Movie Reviews"],"metadata":{"id":"baBUmntVfz6F"}},{"cell_type":"code","source":["## for text mining analysis\n","# Get the 90th percentile box office revenue\n","threshold = movies_cleaned[\"Box Office (Gross USA)\"].quantile(0.9)\n","\n","# Select rows where Box Office is greater than or equal to the 90th percentile\n","top_10_percent_movies = movies_cleaned[movies_cleaned[\"Box Office (Gross USA)\"] >= threshold]\n","top_10_percent_movies.to_csv(\"top_10_percent_movies.csv\")"],"metadata":{"id":"XkgHSAyUkl_H"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","\n","top_10 = pd.read_csv(\"top_10_percent_movies.csv\")\n","top_10.drop(columns=[\"Unnamed: 0\"], inplace=True)"],"metadata":{"id":"7qEzHBO3g0_B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["top_10_movies = top_10[\"movie_name\"].tolist()\n","top_10_movies"],"metadata":{"id":"IDBscRbog1jz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Web Scrapping for Critics and Audience Reviews"],"metadata":{"id":"ljt67OeXlG4g"}},{"cell_type":"code","source":["def scrape_critics_reviews(url, max_clicks=1):\n","    options = Options()\n","    options.add_argument(\"--headless\")\n","    options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\")\n","\n","    # Initialize driver\n","    driver = webdriver.Chrome(options=options)\n","    driver.get(url)\n","\n","    # Click \"Load More\" repeatedly\n","    clicks = 0\n","    while clicks < max_clicks:\n","        try:\n","            #load_more_button = driver.find_element(By.CSS_SELECTOR, \"button.ipc-see-more__button\")  # Adjust selector as needed\n","            rt_button = driver.find_element(By.CSS_SELECTOR, 'rt-button[data-loadmoremanager=\"btnLoadMore:click\"]')\n","            driver.execute_script(\"arguments[0].click();\", rt_button)\n","            time.sleep(3)  # Wait for new items to load\n","            clicks += 1\n","            print(f\"Clicked 'Load More' {clicks} times...\")\n","        except (NoSuchElementException, ElementClickInterceptedException):\n","            print(\"No more 'Load More' button or couldn't click it.\")\n","            break\n","\n","    # After loading all content\n","    soup = BeautifulSoup(driver.page_source, \"lxml\")\n","    driver.quit()\n","\n","    critics_reviews = []\n","    critics_reviews_tags = soup.find_all('div', class_='review-text-container')\n","    if critics_reviews_tags:\n","        for review in critics_reviews_tags:\n","            review_text = review.find('p', class_='review-text').get_text(strip=True)\n","            critics_reviews.append(review_text)\n","    return critics_reviews"],"metadata":{"id":"JEhBW2gbg69_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def scrape_audience_reviews(url, max_clicks=1):\n","    options = Options()\n","    options.add_argument(\"--headless\")\n","    options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\")\n","\n","    # Initialize driver\n","    driver = webdriver.Chrome(options=options)\n","    driver.get(url)\n","\n","    # Click \"Load More\" repeatedly\n","    clicks = 0\n","    while clicks < max_clicks:\n","        try:\n","            #load_more_button = driver.find_element(By.CSS_SELECTOR, \"button.ipc-see-more__button\")  # Adjust selector as needed\n","            rt_button = driver.find_element(By.CSS_SELECTOR, 'rt-button[data-loadmoremanager=\"btnLoadMore:click\"]')\n","            driver.execute_script(\"arguments[0].click();\", rt_button)\n","            time.sleep(3)  # Wait for new items to load\n","            clicks += 1\n","            print(f\"Clicked 'Load More' {clicks} times...\")\n","        except (NoSuchElementException, ElementClickInterceptedException):\n","            print(\"No more 'Load More' button or couldn't click it.\")\n","            break\n","\n","    # After loading all content\n","    soup = BeautifulSoup(driver.page_source, \"lxml\")\n","    driver.quit()\n","\n","    audience_reviews = []\n","    audience_reviews_tags = soup.find_all('div', class_='review-text-container')\n","    if audience_reviews_tags:\n","        for review in audience_reviews_tags:\n","            review_text = review.find('p', {\"class\": re.compile(r\"audience-reviews\")}).get_text(strip=True)\n","            audience_reviews.append(review_text)\n","    return audience_reviews"],"metadata":{"id":"AcQAnDJog7le"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["critics_reviews = {}\n","\n","for title in top_10_movies:\n","    slug = title.lower().replace(\" \", \"_\")\n","    slug = re.sub(r\"[^\\w_]\", \"\", slug)\n","    url = f\"https://www.rottentomatoes.com/m/{slug}/reviews\"\n","\n","    try:\n","        reviews = scrape_critics_reviews(url, max_clicks=1)\n","        critics_reviews[title] = reviews\n","        print(f\"Fetched {len(reviews)} reviews for {title!r}\")\n","    except Exception:\n","        print(f\"Skipping {title!r}: could not scrape {url}\")"],"metadata":{"id":"xAnVyOl2g9Na"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["audience_reviews = {}\n","\n","for title in top_10_movies:\n","    slug = title.lower().replace(\" \", \"_\")\n","    slug = re.sub(r\"[^\\w_]\", \"\", slug)\n","    url = f\"https://www.rottentomatoes.com/m/{slug}/reviews?type=user\"\n","\n","    try:\n","        reviews = scrape_audience_reviews(url, max_clicks=1)\n","        audience_reviews[title] = reviews\n","        print(f\"Fetched {len(reviews)} reviews for {title!r}\")\n","    except Exception:\n","        print(f\"Skipping {title!r}: could not scrape {url}\")"],"metadata":{"id":"wdc7HRcZhAcg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["common = set(critics_reviews) & set(audience_reviews)\n","\n","critics_reviews = { movie: critics_reviews[movie] for movie in common }\n","audience_reviews = { movie: audience_reviews[movie] for movie in common }"],"metadata":{"id":"qQlvN6mZhB29"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Sentiment Analysis"],"metadata":{"id":"s--Ki-OWlJW0"}},{"cell_type":"code","source":["nrc = \"NRC-emotion-lexicon-wordlevel-alphabetized-v0.92.txt\"\n","count=0\n","emotion_dict=dict()\n","with open(nrc,'r') as f:\n","    all_lines = list()\n","    for line in f:\n","        if count < 46:\n","            count+=1\n","            continue\n","        line = line.strip().split('\\t')\n","        if int(line[2]) == 1:\n","            if emotion_dict.get(line[0]):\n","                emotion_dict[line[0]].append(line[1])\n","            else:\n","                emotion_dict[line[0]] = [line[1]]"],"metadata":{"id":"VLQ72ZT9hE_l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def emotion_analyzer(text, emotion_dict=emotion_dict):\n","    emotions = {x for y in emotion_dict.values() for x in y}\n","    emotion_count = dict()\n","    for emotion in emotions:\n","        emotion_count[emotion] = 0\n","\n","    #Analyze the text and normalize by total number of words\n","    total_words = len(text.split())\n","    for word in text.split():\n","        if emotion_dict.get(word):\n","            for emotion in emotion_dict.get(word):\n","                emotion_count[emotion] += 1/len(text.split())\n","    return emotion_count"],"metadata":{"id":"-lfsxkMGhIil"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def convert_to_string(reviews_dict): # critics_reviews/audience_reviews\n","    reviews_emotions = {}\n","    for title, reviews in reviews_dict.items():\n","        # turn the list of review‐strings into one giant string\n","        combined = \" \".join(reviews)\n","        # analyze that combined text\n","        reviews_emotions[title] = emotion_analyzer(combined)\n","    return reviews_emotions"],"metadata":{"id":"h96BzhmnhKbg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["critics_emotions = convert_to_string(critics_reviews)\n","audience_emotions = convert_to_string(audience_reviews)"],"metadata":{"id":"wbb_NuZOhL_I"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def convert_to_df(emotions_dict): # critics_emotions/ audience_emotions\n","    data_list = []\n","    for movie, emotions in emotions_dict.items():\n","        # Create a single row dictionary\n","        row = {'movie': movie}\n","        # Add the emotions - handling both dict and array cases\n","        if isinstance(emotions, dict):\n","            row.update(emotions)\n","        elif isinstance(emotions, np.ndarray):\n","            # Handle numpy array - adjust according to your data structure\n","            pass\n","        data_list.append(row)\n","\n","    # Create DataFrame from list of dictionaries\n","    data_list = pd.DataFrame(data_list)\n","    data_list = data_list.set_index('movie')\n","    return data_list"],"metadata":{"id":"b2LLY5qrhQCz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["critics_emotions = convert_to_df(critics_emotions)\n","audience_emotions = convert_to_df(audience_emotions)"],"metadata":{"id":"BAVLdumNhRiy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["critics_emotions = critics_emotions[['positive','negative']]\n","critics_emotions = critics_emotions.rename(columns={\"positive\": \"critics_positive\", \"negative\": \"critics_negative\"})\n","critics_emotions"],"metadata":{"id":"FS9k5apMhU44"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["audience_emotions = audience_emotions[['positive','negative']]\n","audience_emotions = audience_emotions.rename(columns={\"positive\": \"audience_positive\", \"negative\": \"audience_negative\"})\n","audience_emotions"],"metadata":{"id":"j0Rf0vkZhXjo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["combined_emotions = df_merged = pd.merge(\n","    critics_emotions,\n","    audience_emotions,\n","    on=\"movie\")\n","\n","pct_cols = ['critics_positive','critics_negative','audience_positive','audience_negative']\n","combined_emotions[pct_cols] = combined_emotions[pct_cols] * 100\n","combined_emotions"],"metadata":{"id":"J_SmwAQ4hY7w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["combined_emotions = pd.read_csv(\"combined_emotions.csv\")\n","combined_emotions = combined_emotions.set_index('movie')\n","combined_emotions[\"pos_diff\"] = combined_emotions[\"critics_positive\"] - combined_emotions[\"audience_positive\"]\n","combined_emotions[\"neg_diff\"] = combined_emotions[\"critics_negative\"] - combined_emotions[\"audience_negative\"]\n","combined_emotions"],"metadata":{"id":"xIM8TstZp6W1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sentiment = pd.merge(movies_cleaned, combined_emotions, left_on=\"Movie Name\", right_on=\"movie\", how=\"inner\")\n","sentiment = sentiment.set_index('Movie Name')\n","sentiment.drop(columns=[\"Critic Score\", 'Audience Score', 'Original Language', 'Runtime', 'Box Office (Gross USA)', 'Famous Director', 'Release Year', 'Release Season'], inplace=True)\n","sentiment = sentiment.loc[~sentiment.index.duplicated(keep='first')]\n","sentiment"],"metadata":{"id":"RtEyO7Ed1hw9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sentiment.groupby(\"Rating\")[[\"audience_positive\",\"audience_negative\",\n","                      \"critics_positive\",\"critics_negative\"]].mean()"],"metadata":{"id":"DFfFVN5O3U_U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# takes a column where each entry is a list (or other iterable) and “unnests” it so that each element in the list gets its own row.\n","df_genre = sentiment.assign(Genre=sentiment[\"Genre\"].str.split(\", \")).explode(\"Genre\")\n","df_genre.head()"],"metadata":{"id":"QotFS7DjAFj9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Visualizations"],"metadata":{"id":"D-RAW39QlONe"}},{"cell_type":"code","source":["fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n","\n","# Left plot: positive sentiment comparison\n","axes[0].scatter(\n","    combined_emotions['critics_positive'],\n","    combined_emotions['audience_positive'],\n","    alpha=0.7\n",")\n","axes[0].plot(\n","    [0, combined_emotions['critics_positive'].max()],\n","    [0, combined_emotions['audience_positive'].max()],\n","    'k--', linewidth=1\n",")\n","axes[0].set_xlabel('Critics Positive (%)')\n","axes[0].set_ylabel('Audience Positive (%)')\n","axes[0].set_title('Critics vs Audience Positive Sentiment')\n","axes[0].grid(True)\n","\n","# Right plot: negative sentiment comparison\n","axes[1].scatter(\n","    combined_emotions['critics_negative'],\n","    combined_emotions['audience_negative'],\n","    alpha=0.7,\n","    color='r'\n",")\n","axes[1].plot(\n","    [0, combined_emotions['critics_negative'].max()],\n","    [0, combined_emotions['audience_negative'].max()],\n","    'k--', linewidth=1\n",")\n","axes[1].set_xlabel('Critics Negative (%)')\n","axes[1].set_ylabel('Audience Negative (%)')\n","axes[1].set_title('Critics vs Audience Negative Sentiment')\n","axes[1].grid(True)\n","\n","# Adjust layout and display\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"MbXOGaUphcqB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Sentiment by genre\n","features = [\n","    \"audience_positive\",\n","    \"audience_negative\",\n","    \"critics_positive\",\n","    \"critics_negative\"\n","]\n","titles = [\n","    \"Mean Audience Positive Sentiment by Genre\",\n","    \"Mean Audience Negative Sentiment by Genre\",\n","    \"Mean Critics Positive Sentiment by Genre\",\n","    \"Mean Critics Negative Sentiment by Genre\"\n","]\n","\n","fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n","for ax, feature, title in zip(axes.flatten(), features, titles):\n","    means = df_genre.groupby(\"Genre\")[feature].mean().sort_values()\n","    ax.barh(means.index, means.values)\n","    ax.set_title(title)\n","    ax.set_xlabel(\"Average %\")\n","    ax.set_ylabel(\"Genre\")\n","\n","fig.tight_layout()\n","plt.show()"],"metadata":{"id":"63dGdH73AI83"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 1) compute distance to center\n","xc = combined_emotions['critics_positive'].median()\n","yc = combined_emotions['audience_positive'].median()\n","\n","dx = combined_emotions['critics_positive'] - xc\n","dy = combined_emotions['audience_positive'] - yc\n","dist = np.sqrt(dx*dx + dy*dy)\n","\n","# 2) choose a cutoff: e.g. only top 20% furthest get labeled\n","cutoff = dist.quantile(0.80)\n","\n","fig, ax = plt.subplots(figsize=(10, 6))\n","ax.scatter(combined_emotions['critics_positive'], combined_emotions['audience_positive'], alpha=0.5)\n","ax.axvline(xc, color='gray', linestyle='--')\n","ax.axhline(yc, color='gray', linestyle='--')\n","\n","for movie, row in combined_emotions.iterrows():\n","    if dist[movie] < cutoff:\n","        continue     # skip the “middle” points\n","    xval = row['critics_positive']\n","    yval = row['audience_positive']\n","    if xval >= xc and yval >= yc:\n","        c = 'blue'\n","    elif xval >= xc and yval < yc:\n","        c = 'red'\n","    elif xval < xc and yval >= yc:\n","        c = 'green'\n","    else:\n","        c = 'purple'\n","    ax.text(xval, yval, movie, fontsize=8, color=c,\n","            ha='center', va='center')\n","\n","ax.set_xlabel(\"Critics Positive (%)\")\n","ax.set_ylabel(\"Audience Positive (%)\")\n","ax.set_title(\"Quadrant Plot (only outer 20% labeled)\")\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"Qn1XndlEhgLl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 3. Recommendation LSI Models"],"metadata":{"id":"TzUP19ybgKTR"}},{"cell_type":"markdown","source":["### Web Scrapping for LSI"],"metadata":{"id":"gsmJR9uwjlRR"}},{"cell_type":"code","source":["!pip install imdbpy"],"metadata":{"id":"MuDyx0r2gSGc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["top_10_percent = pd.read_csv(\"top_10_percent_movies.csv\")\n","# Get rid of \"wide\"\n","top_10_percent[\"Release Date (Theaters)\"] = top_10_percent[\"Release Date (Theaters)\"].str.extract(r\"^([A-Za-z]+\\s\\d{1,2},\\s\\d{4})\")\n","\n","# Convert to datetime object and pull out year\n","top_10_percent[\"Release Year\"] = pd.to_datetime(top_10_percent[\"Release Date (Theaters)\"]).dt.year\n","top_10_list = top_10_percent[[\"movie_name\",\"Release Year\"]].values.tolist()"],"metadata":{"id":"nFQzWYywj4v3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["top_10_list"],"metadata":{"id":"1nU15UX4H_Ex","collapsed":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import imdb\n","import time\n","import random\n","from requests.exceptions import HTTPError, ConnectionError, Timeout, ReadTimeout, RequestException\n","\n","def get_movie_details(movie_titles, max_retries=5, initial_backoff=2):\n","    results = dict()\n","    for movie in movie_titles:\n","        # Create a new IMDb instance for each movie to avoid session issues\n","        ia = imdb.IMDb()\n","        print(f\"Searching for: {movie[0]}\")\n","\n","        # Needed to add retries with exponential backoff\n","        for attempt in range(max_retries):\n","            try:\n","                # Set a timeout for the search request\n","                search_results = ia.search_movie(movie[0])\n","\n","                found_movie = None\n","                for result in search_results:\n","                    # Check if year matches if provided\n","                    if len(movie) > 1 and movie[1] and 'year' in result and result['year'] == movie[1]:\n","                        found_movie = result\n","                        break\n","\n","                # If no year match found, use the first result\n","                if not found_movie and search_results:\n","                    found_movie = search_results[0]\n","\n","                if not found_movie:\n","                    print(f\"No results found for {movie[0]}\")\n","                    break\n","\n","                # Add a small delay before fetching details\n","                time.sleep(1)\n","\n","                movie_id = found_movie.movieID\n","                movie_data = ia.get_movie(movie_id)\n","                title = movie_data.get('title')\n","\n","                if 'plot' in movie_data and movie_data['plot']:\n","                    plot = movie_data['plot'][0]\n","                    results[title] = plot\n","                    print(f\"Successfully retrieved data for: {title}\")\n","                else:\n","                    print(f\"No plot found for {title}\")\n","\n","                # Break out of retry loop\n","                break\n","\n","            except (HTTPError, ConnectionError, Timeout, ReadTimeout, RequestException,\n","                    imdb.IMDbDataAccessError, Exception) as e:\n","                # Calculate backoff time with exponential increase and jitter\n","                backoff_time = initial_backoff * (2 ** attempt) * (0.5 + random.random())\n","\n","                if attempt < max_retries - 1:\n","                    print(f\"Error accessing IMDb for {movie[0]}: {str(e)[:100]}... Retrying in {backoff_time:.2f} seconds...\")\n","                    time.sleep(backoff_time)\n","                else:\n","                    print(f\"Failed to get data for {movie[0]} after {max_retries} attempts: {str(e)[:100]}...\")\n","\n","        # Add a delay between movies to avoid rate limiting\n","        time.sleep(2)\n","\n","    return results"],"metadata":{"id":"dnBtkImQj50n"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["comparison_docs = get_movie_details(top_10_list)"],"metadata":{"id":"Ehib5eG6j7sR","collapsed":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Write to CSV so I don't need to run the webscrapping again\n","comparison_docs_df = pd.DataFrame.from_dict(comparison_docs, orient='index')\n","\n","# Reset index to convert the movie names into a regular column\n","comparison_movies = comparison_docs_df.reset_index()\n","comparison_movies = comparison_movies.rename(columns={\"index\": \"Movie Name\", 0: \"Summary\"})\n","\n","# Save to CSV without the index column\n","comparison_movies.to_csv(\"comparison_movie_sums.csv\", index=False)"],"metadata":{"id":"E-MsZsxnj8an"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Getting Comparison Movies for LSI"],"metadata":{"id":"WIHjIFKjj9fR"}},{"cell_type":"code","source":["from selenium import webdriver\n","from selenium.webdriver.chrome.options import Options\n","from selenium.webdriver.common.by import By\n","from selenium.common.exceptions import ElementClickInterceptedException, NoSuchElementException\n","from bs4 import BeautifulSoup\n","import time\n","\n","def movie_web_scrapping_lsi(start_url, max_clicks=10):\n","    # Setup Chrome options\n","    options = Options()\n","    options.add_argument(\"--headless\")\n","    options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\")\n","\n","    # Initialize driver\n","    driver = webdriver.Chrome(options=options)\n","    driver.get(start_url)\n","\n","    # Click \"Load More\" repeatedly\n","    clicks = 0\n","    while clicks < max_clicks:\n","        try:\n","            load_more_button = driver.find_element(By.CSS_SELECTOR, \"button.ipc-see-more__button\")\n","            driver.execute_script(\"arguments[0].click();\", load_more_button)\n","            time.sleep(1)  # Wait for new items to load\n","            clicks += 1\n","            print(f\"Clicked 'Load More' {clicks} times...\")\n","        except (NoSuchElementException, ElementClickInterceptedException):\n","            print(\"No more 'Load More' button or couldn't click it.\")\n","            break\n","\n","    # After loading all content\n","    soup = BeautifulSoup(driver.page_source, \"lxml\")\n","    driver.quit()\n","\n","    # Initialize list to store [title, year] pairs\n","    movie_data = {}\n","\n","    # Find all movie containers\n","    movie_containers = soup.find_all(\"div\", {\"class\": \"ipc-metadata-list-summary-item__c\"})\n","\n","    for container in movie_containers:\n","        try:\n","            # Extract title\n","            title_element = container.find(\"h3\", {\"class\": \"ipc-title__text\"})\n","            if title_element:\n","                title = title_element.get_text().split(\".\")[1].strip()\n","\n","                # Extract year\n","                year_element = container.find(\"span\", {\"class\": \"sc-5179a348-7 idrYgr dli-title-metadata-item\"})\n","                year = year_element.get_text() if year_element else \"Unknown\"\n","\n","                # Add [title, year] to the movie_data list\n","                movie_data[title] = year\n","        except Exception as e:\n","            continue\n","\n","    return movie_data\n"],"metadata":{"id":"5ch1DMFukBvK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# movies from 1970 - 1990\n","reference_movies_lsi = movie_web_scrapping_lsi(\"https://www.imdb.com/search/title/?title_type=feature&release_date=1970-01-01,1990-01-01&languages=en\", max_clicks = 315)"],"metadata":{"id":"hK-2dIphkDCo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Write to CSV so I don't need to run the webscrapping again\n","reference_movies = pd.DataFrame.from_dict(reference_movies_lsi, orient='index')\n","\n","# Reset index to convert the movie names into a regular column\n","reference_movies = reference_movies.reset_index()\n","reference_movies = reference_movies.rename(columns={\"index\": \"Movie Name\", 0: \"Year\"})\n","\n","# Save to CSV without the index column\n","reference_movies.to_csv(\"reference_movies.csv\", index=False)"],"metadata":{"id":"i9G_yJf9kFEt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["lsi_reference_movies = pd.read_csv(\"reference_movies.csv\")\n","lsi_reference_movies_list = lsi_reference_movies.values.tolist()"],"metadata":{"id":"NbMtVgy_kGO3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Run it in batches\n","reference_movie_sums_11 = get_movie_details(lsi_reference_movies_list[8000:])"],"metadata":{"id":"o21uEbE4kHYd","collapsed":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Write to CSV so I don't need to run the webscrapping again\n","reference_movie_sums_csv = pd.DataFrame.from_dict(reference_movie_sums_11, orient='index')\n","\n","# Reset index to convert the movie names into a regular column\n","reference_movie_sums_csv = reference_movie_sums_csv.reset_index()\n","reference_movie_sums_csv = reference_movie_sums_csv.rename(columns={\"index\": \"Movie Name\", 0: \"Summary\"})\n","\n","# Save to CSV without the index column\n","reference_movie_sums_csv.to_csv(\"reference_movies_sum_11.csv\", index=False)"],"metadata":{"id":"7L83VphzkKy9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Merge all batched csvs\n","filenames = [f\"reference_movies_sum_{i}.csv\" for i in range (1,12)]\n","reference_movie_sums_df = [pd.read_csv(filename) for filename in filenames]\n","reference_movie_sums_final = pd.concat(reference_movie_sums_df, ignore_index=True)\n","reference_movie_sums_final.to_csv(\"reference_movie_sums.csv\")"],"metadata":{"id":"xQGR81iR0cpi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##Build LSI"],"metadata":{"id":"-wQmVWz65BZg"}},{"cell_type":"code","source":["import nltk\n","\n","common_corpora = [\n","    'gutenberg', 'genesis', 'inaugural', 'nps_chat', 'webtext',\n","    'punkt', 'stopwords', 'wordnet', 'omw-1.4',\n","    'averaged_perceptron_tagger', 'maxent_ne_chunker', 'words',\n","    'reuters', 'movie_reviews', 'treebank', 'tagsets'\n","]\n","\n","for corpus in common_corpora:\n","    nltk.download(corpus)\n"],"metadata":{"id":"Ce9w2F5S6s9C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install numpy==1.24.3\n","!pip install -U gensim\n","# !pip install wordcloud\n","from wordcloud import WordCloud, STOPWORDS\n","import nltk\n","from nltk.corpus import PlaintextCorpusReader\n","from nltk import sent_tokenize,word_tokenize\n","from nltk.book import *\n","# import gensim.summarization\n","from gensim import corpora, models, similarities\n"],"metadata":{"id":"XE5Qm90f8DR-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###Reference Docs"],"metadata":{"id":"Bo4Iol7d5D5l"}},{"cell_type":"code","source":["import pandas as pd"],"metadata":{"id":"Em8Y9afa8Z8O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["reference_movies = pd.read_csv(\"reference_movie_sums.csv\")"],"metadata":{"id":"6Op3t4Di33hS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["reference_movies_sums = reference_movies[\"Summary\"].to_list()\n","reference_movies_names = reference_movies[\"Movie Name\"].to_list()"],"metadata":{"id":"6_6AA3IP5KYF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# reference_movies.to_csv(\"Reference Movies.csv\")"],"metadata":{"id":"703rQnXoDDgQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Code for LSI model for summaries goes here\n","documents = [doc for doc in reference_movies_sums]\n","texts = [[word for word in document.lower().split()\n","        if word not in STOPWORDS and word.isalnum()]\n","        for document in documents]\n","dictionary_summary = corpora.Dictionary(texts)\n","corpus_summary = [dictionary_summary.doc2bow(text) for text in texts]\n","\n","lsi_ref_summary = models.LsiModel(corpus_summary, id2word=dictionary_summary, num_topics=150)"],"metadata":{"id":"x_-p6xKn5rM-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["comparison_movies = pd.read_csv(\"comparison_movie_sums.csv\")\n","comparison_movies_sums = comparison_movies[\"Summary\"].to_list()\n","comparison_movies_names = comparison_movies[\"Movie Name\"].to_list()"],"metadata":{"id":"6SIuAcnX9t9K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from gensim.similarities.docsim import Similarity\n","from gensim import corpora, models, similarities\n","import warnings"],"metadata":{"id":"xMv1P_a5BWG6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["index = similarities.MatrixSimilarity(lsi_ref_summary[corpus_summary])\n","warnings.filterwarnings(\"ignore\")\n","table_data = []\n","for i, movie_summary in enumerate(comparison_movies_sums):\n","    words = [word for word in movie_summary.lower().split()\n","              if word not in STOPWORDS and word.isalnum()]\n","    vec_bow = dictionary_summary.doc2bow(words)\n","    vec_lsi = lsi_ref_summary[vec_bow]\n","    sims = index[vec_lsi]\n","    sims = sorted(enumerate(sims), key=lambda item: -item[1])\n","    most_similar = sims[0]\n","\n","    # Store the result\n","    table_data.append({\n","        \"Movie\": comparison_movies_names[i],\n","        \"Most Similar Movie\": reference_movies_names[most_similar[0]],\n","        \"Similarity Score\": most_similar[1]\n","    })\n","\n","similarity_df = pd.DataFrame(table_data)"],"metadata":{"id":"4QEV3rHW6ZZC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["index = similarities.MatrixSimilarity(lsi_ref_summary[corpus_summary])\n","warnings.filterwarnings(\"ignore\")\n","table_data = []\n","for i, movie_summary in enumerate(comparison_movies_sums):\n","    words = [word for word in movie_summary.lower().split()\n","             if word not in STOPWORDS and word.isalnum()]\n","    vec_bow = dictionary_summary.doc2bow(words)\n","    vec_lsi = lsi_ref_summary[vec_bow]\n","    sims = index[vec_lsi]\n","    sim_list = list(enumerate(sims))\n","    sorted_sims = sorted(sim_list, key=lambda item: -item[1])\n","\n","    most_similar = None\n","    for ref_idx, similarity in sorted_sims:\n","        if comparison_movies_names[i] != reference_movies_names[ref_idx]:\n","            most_similar = (ref_idx, similarity)\n","            break\n","\n","    if most_similar:\n","        table_data.append({\n","            \"Movie\": comparison_movies_names[i],\n","            \"Most Similar Movie\": reference_movies_names[most_similar[0]],\n","            \"Similarity Score\": most_similar[1]\n","        })\n","    else:\n","        print(f\"No unique match found for: {comparison_movies_names[i]}\")\n","\n","similarity_df = pd.DataFrame(table_data)"],"metadata":{"id":"SEvhKWAqusfi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["similarity_df.to_csv(\"lsi_output.csv\")"],"metadata":{"id":"a_b4lKgt-RbH"},"execution_count":null,"outputs":[]}]}